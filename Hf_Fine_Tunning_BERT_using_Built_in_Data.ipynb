{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO7oMkOiw6YdcRYJQDm/YN1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "09617d005c274139ada3826cf4d17b34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f717d8c7cf3c45b8af2bf72b2afa0849",
              "IPY_MODEL_a2b739ec23dc437da7859a6ac6a85516",
              "IPY_MODEL_cffe8374208e4c0cb7a24cd743870321"
            ],
            "layout": "IPY_MODEL_b9b0c67271ce4a21993aa57324503588"
          }
        },
        "f717d8c7cf3c45b8af2bf72b2afa0849": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b24a9a283cdb4e43bac62bf72b6a3122",
            "placeholder": "​",
            "style": "IPY_MODEL_329e3f73fd0949219af49f14f42a0adf",
            "value": "Map: 100%"
          }
        },
        "a2b739ec23dc437da7859a6ac6a85516": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad7f7aee55c543949713a0fd7b37711c",
            "max": 872,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_da6b60f19af44eb2b934a4395c402c4d",
            "value": 872
          }
        },
        "cffe8374208e4c0cb7a24cd743870321": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b90c2bb2c6d240c497836d8cfae2fac9",
            "placeholder": "​",
            "style": "IPY_MODEL_e930c3ae95cb4aaaa9e243b2103f7f0a",
            "value": " 872/872 [00:00&lt;00:00, 7129.07 examples/s]"
          }
        },
        "b9b0c67271ce4a21993aa57324503588": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b24a9a283cdb4e43bac62bf72b6a3122": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "329e3f73fd0949219af49f14f42a0adf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad7f7aee55c543949713a0fd7b37711c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da6b60f19af44eb2b934a4395c402c4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b90c2bb2c6d240c497836d8cfae2fac9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e930c3ae95cb4aaaa9e243b2103f7f0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rami-RK/HugingFace_Transformers/blob/main/Hf_Fine_Tunning_BERT_using_Built_in_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Huggingface: Fine Tunning BERT using Built in Data**"
      ],
      "metadata": {
        "id": "iCwQ6LZx2C8z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Objectives:\n",
        "\n",
        "At the end of the experiment you will be able to understand  :\n",
        "\n",
        "* How datasets are represented in HF\n",
        "* Trainer and trainingArguments objects\n",
        "* Computing Metrics\n",
        "* Saving and loading the trained model"
      ],
      "metadata": {
        "id": "KM-pOa7S1OLC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate -U"
      ],
      "metadata": {
        "id": "r3iM7nYp_J5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "BjmSAoN29QTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hugging Face Datasets Library\n"
      ],
      "metadata": {
        "id": "DmLOuovi1jSk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOpFIwY9lzZ7"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Loading the dataset**\n",
        "Built in data sets are included with the data sets package. Using a single line of code, we can load in the data set  which  are well formatted  and processed for us to use."
      ],
      "metadata": {
        "id": "gnEmSp3x2RT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "#rd1=load_dataset(\"amazon_polarity\") # dataset for sentiment analysis\n",
        "rd2=load_dataset(\"glue\",\"sst2\")     # Part of GLUE Benchmark"
      ],
      "metadata": {
        "id": "LZsbllFu1wEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calling the load data set function, returns a data set dict object, which is like a dictionary that may contain multiple data sets like -  a train dataset, validation dataset and test dataset."
      ],
      "metadata": {
        "id": "3Dta_Z-88-Cv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rd2"
      ],
      "metadata": {
        "id": "rjGwwmis2YVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting different data and individual entries"
      ],
      "metadata": {
        "id": "IjHlKLBw-GaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rd2['train']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulnMdowg2Yb-",
        "outputId": "47e82039-46dc-4419-95de-35946f6f4c28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['sentence', 'label', 'idx'],\n",
              "    num_rows: 67349\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(rd2['train'], '\\n')\n",
        "type(rd2['train'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSQ8sSVh2Ykm",
        "outputId": "b0b056d4-d0b1-4205-aac1-4c2a8c91ce03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['sentence', 'label', 'idx'],\n",
            "    num_rows: 67349\n",
            "}) \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datasets.arrow_dataset.Dataset"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rd2['train'].data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8wVofQM8F-N",
        "outputId": "036da58b-721c-443c-e2a1-77bb1687c970"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MemoryMappedTable\n",
              "sentence: string\n",
              "label: int64\n",
              "idx: int32\n",
              "----\n",
              "sentence: [[\"hide new secretions from the parental units \",\"contains no wit , only labored gags \",\"that loves its characters and communicates something rather beautiful about human nature \",\"remains utterly satisfied to remain the same throughout \",\"on the worst revenge-of-the-nerds clichés the filmmakers could dredge up \",...,\"you wish you were at home watching that movie instead of in the theater watching this one \",\"'s no point in extracting the bare bones of byatt 's plot for purposes of bland hollywood romance \",\"underdeveloped \",\"the jokes are flat \",\"a heartening tale of small victories \"],[\"suspense , intriguing characters and bizarre bank robberies , \",\"a gritty police thriller with all the dysfunctional family dynamics one could wish for \",\"with a wonderful ensemble cast of characters that bring the routine day to day struggles of the working class to life \",\"nonetheless appreciates the art and reveals a music scene that transcends culture and race . \",\"do we really need the tiger beat version ? \",...,\"when there 's nothing else happening \",\"on cable \",\"it with ring , \",\"far from a groundbreaking endeavor \",\"that these women are spectacular \"],...,[\"it does turn out to be a bit of a cheat in the end \",\"may be convinced that he has something significant to say \",\"to be both hugely entertaining and uplifting . \",\", boredom never takes hold . \",\"left to work with , sort of like michael jackson 's nose \",...,\"from a severe case of hollywood-itis \",\"the very best of them \",\"thrills , \",\"'s attracting audiences to unfaithful \",\"impressively delicate range \"],[\"starts off promisingly but then proceeds to flop \",\"distinguished actor \",\"on their parents ' anguish \",\"pays off and is effective if you stick with it \",\"is n't particularly funny \",...,\"a delightful comedy \",\"anguish , anger and frustration \",\"at achieving the modest , crowd-pleasing goals it sets for itself \",\"a patient viewer \",\"this new jangle of noise , mayhem and stupidity must be a serious contender for the title . \"]]\n",
              "label: [[0,0,1,0,0,...,0,0,0,0,1],[1,1,1,1,0,...,0,0,1,0,1],...,[0,0,1,1,0,...,0,1,1,1,1],[0,1,0,1,0,...,1,0,1,1,0]]\n",
              "idx: [[0,1,2,3,4,...,995,996,997,998,999],[1000,1001,1002,1003,1004,...,1995,1996,1997,1998,1999],...,[66000,66001,66002,66003,66004,...,66995,66996,66997,66998,66999],[67000,67001,67002,67003,67004,...,67344,67345,67346,67347,67348]]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rd2['train'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGtKkDOu2LN0",
        "outputId": "b98542a2-71df-494f-9495-7a40714c06fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sentence': 'hide new secretions from the parental units ',\n",
              " 'label': 0,\n",
              " 'idx': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rd2['train'][10:13]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoAcjN388lU2",
        "outputId": "43a93dbc-6e1b-4934-fd87-0e40c909e535"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sentence': ['goes to absurd lengths ',\n",
              "  \"for those moviegoers who complain that ` they do n't make movies like they used to anymore \",\n",
              "  \"the part where nothing 's happening , \"],\n",
              " 'label': [0, 0, 0],\n",
              " 'idx': [10, 11, 12]}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rd2['train'].features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yas_HvF_2AX_",
        "outputId": "ddd33669-3f09-42f1-baa5-b3d39a179e36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sentence': Value(dtype='string', id=None),\n",
              " 'label': ClassLabel(names=['negative', 'positive'], id=None),\n",
              " 'idx': Value(dtype='int32', id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Tokenization with DataSets**\n",
        "Recall that previously, we mentioned the need for truncation, padding and converting the tokenized data into PyTorch Tensors. Here, all of these steps will be handled  behind the scenes and no need to do anything. We are going to do is to partially apply the tokenizer to the data set dict object.\n",
        "\n"
      ],
      "metadata": {
        "id": "Ik25FJ1g9HIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer"
      ],
      "metadata": {
        "id": "DL1qiWY89BEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "nNwNJ2a39LCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_sentence = tokenizer(rd2['train'][0:3]['sentence'])\n",
        "from pprint import pprint\n",
        "pprint(tokenized_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3h1joIIq9kwH",
        "outputId": "352bebf1-3d6f-488d-84b5-f9583046ae3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "                    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "                    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            " 'input_ids': [[101, 5342, 2047, 3595, 8496, 2013, 1996, 18643, 3197, 102],\n",
            "               [101,\n",
            "                3397,\n",
            "                2053,\n",
            "                15966,\n",
            "                1010,\n",
            "                2069,\n",
            "                4450,\n",
            "                2098,\n",
            "                18201,\n",
            "                2015,\n",
            "                102],\n",
            "               [101,\n",
            "                2008,\n",
            "                7459,\n",
            "                2049,\n",
            "                3494,\n",
            "                1998,\n",
            "                10639,\n",
            "                2015,\n",
            "                2242,\n",
            "                2738,\n",
            "                3376,\n",
            "                2055,\n",
            "                2529,\n",
            "                3267,\n",
            "                102]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By calling the map method and passing in a tokenized function, the data set library automatically knows it should apply the same function to every data set i.e.train, validation and test.\n",
        "\n",
        " Note that in this example we apply only truncation but not padding or conversion into Pytorch Tensors. This will be handled behind the scenes by the trainer object we create later."
      ],
      "metadata": {
        "id": "REvSFVnOCvZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_fn(batch):\n",
        "  return tokenizer(batch['sentence'],truncation=True)"
      ],
      "metadata": {
        "id": "85D3Ls-3-EnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets=rd2.map(tokenize_fn,batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "09617d005c274139ada3826cf4d17b34",
            "f717d8c7cf3c45b8af2bf72b2afa0849",
            "a2b739ec23dc437da7859a6ac6a85516",
            "cffe8374208e4c0cb7a24cd743870321",
            "b9b0c67271ce4a21993aa57324503588",
            "b24a9a283cdb4e43bac62bf72b6a3122",
            "329e3f73fd0949219af49f14f42a0adf",
            "ad7f7aee55c543949713a0fd7b37711c",
            "da6b60f19af44eb2b934a4395c402c4d",
            "b90c2bb2c6d240c497836d8cfae2fac9",
            "e930c3ae95cb4aaaa9e243b2103f7f0a"
          ]
        },
        "id": "viH6eIVt-Pgw",
        "outputId": "baf63a33-1a25-4dc7-d185-13c67367b342"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/872 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "09617d005c274139ada3826cf4d17b34"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Loading Pre-Trained Model**"
      ],
      "metadata": {
        "id": "TPXfBiYpElKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "model =AutoModelForSequenceClassification.from_pretrained(checkpoint,num_labels=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHeD1YZu-iA9",
        "outputId": "71a47a26-d936-4332-8f4c-ac7025a8434d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'classifier.weight', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qecYc5gc-iDY",
        "outputId": "08ee328b-86c2-4fae-bdaf-d218edf9dd63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "transformers.models.distilbert.modeling_distilbert.DistilBertForSequenceClassification"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "5zCs4qGmALUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCX07y3jAMgI",
        "outputId": "416d7aa0-eac4-42c0-dda4-31c9f63fd6b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "summary(model)"
      ],
      "metadata": {
        "id": "_48MxpMs9LFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Adding custom classifier layter and Freezing/Un-Freezing different layers**"
      ],
      "metadata": {
        "id": "OEaFCpYAFLzC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "     if name.startswith(\"distilbert\"): # choose whatever you like here\n",
        "        param.requires_grad = False"
      ],
      "metadata": {
        "id": "Vl9qw4l2IPIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying of layers gradient\n",
        "for name, param in model.named_parameters():\n",
        "     print(name, param.requires_grad)"
      ],
      "metadata": {
        "id": "-rpzN_c6HRTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Modifying last classifier layers**"
      ],
      "metadata": {
        "id": "lF5rsURm5AQW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "LORB42Uf4wkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.pre_classifier"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDorephi7hes",
        "outputId": "8682aa78-1a1e-4e26-8b32-ac821e542fcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=768, out_features=384, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.pre_classifier)\n",
        "model.pre_classifier = torch.nn.Linear(768,384)\n",
        "print(model.pre_classifier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4F6lG1z79LHo",
        "outputId": "b248e92a-9541-4115-9f16-823f52eb9a21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear(in_features=768, out_features=768, bias=True)\n",
            "Linear(in_features=768, out_features=384, bias=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.classifier)\n",
        "model.classifier = torch.nn.Linear(384,2)\n",
        "print(model.classifier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhfOZTPTBxTe",
        "outputId": "79b5483d-9f7a-4ed2-b2b8-73514e6849c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear(in_features=768, out_features=2, bias=True)\n",
            "Linear(in_features=384, out_features=2, bias=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "NbgkLalM9NIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Adding extra layer on top**"
      ],
      "metadata": {
        "id": "CJhJo1938YWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy"
      ],
      "metadata": {
        "id": "3uKXEnSi9hjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cp_model = copy.deepcopy(model)"
      ],
      "metadata": {
        "id": "uGoORHUh8hEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cp_model.classifier = torch.nn.Sequential(\n",
        "    (torch. nn.Linear(384, 192)),\n",
        "    torch.nn.Dropout(0.1),\n",
        "    (torch.nn.Linear(192, 2)))"
      ],
      "metadata": {
        "id": "KtADX5zV8Xen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cp_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHpHqbFh5xTD",
        "outputId": "49ed1ba9-9c5e-4e34-9c73-5d1a3af04caa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBertForSequenceClassification(\n",
              "  (distilbert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pre_classifier): Linear(in_features=768, out_features=384, bias=True)\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=384, out_features=192, bias=True)\n",
              "    (1): Dropout(p=0.1, inplace=False)\n",
              "    (2): Linear(in_features=192, out_features=2, bias=True)\n",
              "  )\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params_before=[]\n",
        "for  name,p in model.named_parameters():\n",
        "  params_before.append(p.detach().cpu().numpy())"
      ],
      "metadata": {
        "id": "Hpp24FTuCnNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params_before"
      ],
      "metadata": {
        "id": "CikrjMifDBbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Metrics**\n",
        "\n",
        "In HuggingFace, there are predefined metrics for the built in data sets and we are going to use that but we can define custom metrics as well.\n",
        "\n",
        "Specifically, there is a function called the load metric, also part of the data sets library. The arguments to this happens to be the same as the arguments into load data set for this example.\n",
        "\n",
        "More generally, however, you can pass in an argument to specify a specific metric like the Blue score or a python file where you've defined your own computations."
      ],
      "metadata": {
        "id": "wJficH7a97nY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_metric\n",
        "metric =load_metric(\"glue\",\"sst2\")"
      ],
      "metadata": {
        "id": "icGBrZSrDIVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "But,  we cannot pass this metric into the trainer directly. we need to define another function to do some extra work.\n",
        "\n",
        "Firstly, the metric we get back from `load_metric` is an object which has a method called `compute`, which will return a dictionary containing the computed metrics for a given task. This compute method it takes in to erase the predictions and the targets called a references.\n",
        "\n",
        "This will give us back a dictionary with the value of the metric or metrics with their names as keys."
      ],
      "metadata": {
        "id": "WfE5aqKNHNUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metric.compute(predictions=[1,0,1], references=[1,0,0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9J5Vi6w7DVIR",
        "outputId": "edb9a88e-25e3-4946-c7cb-36f276ae9597"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.6666666666666666}"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(logits_and_labels):\n",
        "  logits, labels = logits_and_labels\n",
        "  predictions =np.argmax(logits,axis=-1)\n",
        "  return metric.compute(predictions=predictions,references=labels)"
      ],
      "metadata": {
        "id": "Eu5nmiAZDuU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Training argument class**\n",
        "\n",
        "\n",
        "The training arguments class is like a training configuration. It allows to specify things like  - `where to save the outputs of the training process, how often to compute metrics, how many epochs to train for the learning rate, and many more`. There are tons of arguments into the constructor for this class. So check out the documentation.\n",
        "\n",
        "Note that the HuggingFace trainer uses an optimizer called **`Adam W`** by default, which is a slight variation of Adam.This is essentially built in and it's good enough for our purposes.If you want to use a different optimizer, you can always write your own custom training loop in plain Pytorch syntax as well."
      ],
      "metadata": {
        "id": "rnfX6i--9OWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments"
      ],
      "metadata": {
        "id": "hyj52cyV-hVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    'sample_trainer',\n",
        "    evaluation_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    num_train_epochs=1\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "D1J_saYU-h-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Trainer**\n",
        "\n",
        "Trainer object is what we use to run the training process. The arguments to the constructor are quite simple. We pass in the model, the trainer arguments, the training data set, the validation data set, the tokenizer and the metrics.\n",
        "\n",
        "Now, just call `trainer` and apply `train` method to train.\n",
        "\n"
      ],
      "metadata": {
        "id": "B3EniE6y9vFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer"
      ],
      "metadata": {
        "id": "UXz8DGFXEzw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    cp_model,\n",
        "    training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset = tokenized_datasets[\"validation\"],\n",
        "    tokenizer =tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "yozHJeifEGfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n",
        " # ~ 2 mint for tunning just last classifier layers\n",
        " # ~ 8 mint for tunning whole architecture"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "fNpRurWpE_26",
        "outputId": "d9ae2b73-9cec-4648-e6ea-e0e33fbf463b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8419' max='8419' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [8419/8419 02:18, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.366800</td>\n",
              "      <td>0.383758</td>\n",
              "      <td>0.830275</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=8419, training_loss=0.3795243134222768, metrics={'train_runtime': 138.2525, 'train_samples_per_second': 487.145, 'train_steps_per_second': 60.896, 'total_flos': 515920678674600.0, 'train_loss': 0.3795243134222768, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Saving the model**"
      ],
      "metadata": {
        "id": "ZcgsEYJlKbR0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model('saved_model')"
      ],
      "metadata": {
        "id": "r0-EFIfIGAwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3SgH3qXGA1S",
        "outputId": "5a0eb671-8602-4e96-b7bf-60741827cfb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data  sample_trainer  saved_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Loading the saved model**"
      ],
      "metadata": {
        "id": "6GxwVdGLKgPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "zh3Dvzz-GBEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_model = pipeline('text-classification',model='saved_model',device=0)"
      ],
      "metadata": {
        "id": "SKjG3Gm0Gb1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_model('this is not a good book to read')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5JKzUUTGk1D",
        "outputId": "a0b52767-4a70-4288-a316-050c62b7b5db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'LABEL_0', 'score': 0.8451212644577026}]"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Checking whether all parameters have updated or not**"
      ],
      "metadata": {
        "id": "HdqU6lCQuYf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params_after=[]\n",
        "for  name,p in model.named_parameters():\n",
        "  params_after.append(p.detach().cpu().numpy())"
      ],
      "metadata": {
        "id": "DciFZ0pyud5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for p1,p2 in zip(params_before, params_after):\n",
        "  print(np.sum(np.abs(p1-p2)))"
      ],
      "metadata": {
        "id": "0atso-cNusSU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}